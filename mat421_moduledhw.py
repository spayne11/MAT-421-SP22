# -*- coding: utf-8 -*-
"""mat421.moduleDhw.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XDe0RWto6QknOpsF0aWD_r36VO4xIrFN

Sydney Payne

Spring 2022 - MAT 421

Module D Homework

Subspace
"""

import numpy as np
P_z=np.matrix([[0,0,0],[0,0,0],[0,0,1]])
P_xy=np.matrix([[1,0,0],[0,1,0],[0,0,0]])

b=np.matrix([2,3,4])
p_xy=P_xy*b.T
p_z=P_z*b.T

def gen_projection_matrix(a10):
  return np.outer(a10,a10)/a10.dot(a10)

def calc_projection(b,P):
  return P.dot(b.T)

a10=np.array([1,2,2])
b=np.array([1,1,1])

P=gen_projection_matrix(a10)
p=calc_projection(b,P)

from numpy.random import default_rng
from scipy.linalg import hadamard, subspace_angles
rng = default_rng()
H = hadamard(4)
print(H)

subspace_angles(H[:, :2], H[:, :2]) <= 2 * np.finfo(float).eps

x = rng.standard_normal((4, 3))
np.rad2deg(subspace_angles(x[:, :2], x[:, [2]]))

"""Null Space"""

# Python code: calculating null space

import numpy as np
from numpy.linalg import svd

def nullspace(A, atol=1e-13, rtol=0):
    """Compute an approximate basis for the nullspace of A.

    The algorithm used by this function is based on the singular value
    decomposition of `A`.

    Parameters
    ----------
    A : ndarray
        A should be at most 2-D.  A 1-D array with length k will be treated
        as a 2-D with shape (1, k)
    atol : float
        The absolute tolerance for a zero singular value.  Singular values
        smaller than `atol` are considered to be zero.
    rtol : float
        The relative tolerance.  Singular values less than rtol*smax are
        considered to be zero, where smax is the largest singular value.

    If both `atol` and `rtol` are positive, the combined tolerance is the
    maximum of the two; that is::
        tol = max(atol, rtol * smax)
    Singular values smaller than `tol` are considered to be zero.

    Return value
    ------------
    ns : ndarray
        If `A` is an array with shape (m, k), then `ns` will be an array
        with shape (k, n), where n is the estimated dimension of the
        nullspace of `A`.  The columns of `ns` are a basis for the
        nullspace; each element in numpy.dot(A, ns) will be approximately
        zero.
    """

    A = np.atleast_2d(A)
    u, s, vh = svd(A)
    tol = max(atol, rtol * s[0])
    nnz = (s >= tol).sum()
    ns = vh[nnz:].conj().T
    return ns

A=[(0,1),(0,1)]

nullspace(A,1e-13,0)

A1=[(3,5,3),(3,4,7),(6,8,2)]
nullspace(A1,1e-13,0)

"""Orthogonality"""

#A python program to illustrate orthogonal vector
#Import numpy module
import numpy

v1=[[1,-2,4]]
v2=[[2,5,2]]

transposeofv1=numpy.transpose(v1)
result=numpy.dot(v2,transposeofv1)
print("Result=",result)

"""Orthonormal"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

v11=np.array([1,-2,4])
v21=np.array([2,5,2])

dot_product=np.sum(v11*v21)
print("The dot product of v11 and v21 is",dot_product)

n11=np.sqrt(np.sum(v11*v11))
n21=np.sqrt(np.sum(v21*v21))

print('The L2 norm of v11 is',n11)
print('The L2 norm of v21 is',n21)

n111=np.linalg.norm(v11,ord=2)
n211=np.linalg.norm(v21,ord=2)

print('The L2 norm of v11 is',n111)
print('The L2 norm of v21 is',n211)

"""Eigenvalues and Eignevectors"""

import numpy as np
from numpy.linalg import eig

a1=np.array([[0,2],[2,3]])
w1,v1=eig(a1)
print('E-value:',w1)
print('E-vector',v1)

a2=np.array([[2,2,4],[1,3,5],[2,3,4]])
w2,v2=eig(a2)
print('E-value:',w2)
print('E-vector',v2)

a3=np.array([[0,-1],[1,0]])
w3,v3=eig(a3)
print('E-value:',w3)
print('E-vector',v3)

"""Gram-Schmidt Process"""

import numpy as np

def gs(X4):
  Q,R=np.linalg.qr(X4)
  return Q

m4=np.array([[1,1,1],[1,1,0],[1,0,0]])
gs(m4)

"""Diagonalizatoin / Hamiltonian """

import numpy as np


def doApplyHam(psiIn: np.ndarray,
               hloc: np.ndarray,
               N: int,
               usePBC: bool):
  """
  Applies local Hamiltonian, given as sum of nearest neighbor terms, to
  an input quantum state.
  Args:
    psiIn: vector of length d**N describing the quantum state.
    hloc: array of ndim=4 describing the nearest neighbor coupling.
    N: the number of lattice sites.
    usePBC: sets whether to include periodic boundary term.
  Returns:
    np.ndarray: state psi after application of the Hamiltonian.
  """
  d = hloc.shape[0]
  psiOut = np.zeros(psiIn.size)
  for k in range(N - 1):
    # apply local Hamiltonian terms to sites [k,k+1]
    psiOut += np.tensordot(hloc.reshape(d**2, d**2),
                           psiIn.reshape(d**k, d**2, d**(N - 2 - k)),
                           axes=[[1], [1]]).transpose(1, 0, 2).reshape(d**N)

  if usePBC:
    # apply periodic term
    psiOut += np.tensordot(hloc.reshape(d, d, d, d),
                           psiIn.reshape(d, d**(N - 2), d),
                           axes=[[2, 3], [2, 0]]
                           ).transpose(1, 2, 0).reshape(d**N)

  return psiOut

"""Linear Regression"""

import numpy as np
from sklearn.linear_model import LinearRegression

x6=np.array([5,15,25,35,45,55]).reshape((-1,1))
y6=np.array([5,20,14,32,22,38])
print('x=',x6)
print('y=',y6)

model=LinearRegression().fit(x6,y6)

r_sq=model.score(x6,y6)
print('coefficient of determination:',r_sq)

print('intercept:',model.intercept_)
print('slope:',model.coef_)

"""Decompostion"""

from math import acos, cos

# Compute the inner sum
def integral(a_i, h, n):
    integ = 0.0
    for j in range(n):
        a_ij = a_i + (j + 0.5) * h
        integ += cos(a_ij) * h
    return integ
    
pi = 3.14159265359
p = 4
n = 500
a = 0.0
b = pi / 2.0
h = (b - a) / (n * p)

integral_sum = 0.0

# Compute the outer sum
for i in range(p):
    a_i = a + i * n * h
    integral_sum += integral(a_i, h, n)
    
print("The integral = ", integral_sum)

"""QR Decompostion"""

import pprint
import scipy
import scipy.linalg   # SciPy Linear Algebra Library

A9 = scipy.array([[12, -51, 4], [6, 167, -68], [-4, 24, -41]])  # From the Wikipedia Article on QR Decomposition
Q, R = scipy.linalg.qr(A9)

print("A:",A9)
print("Q:",Q)
print("R:",R)

from math import sqrt
from pprint import pprint

def mult_matrix(M, N):
    """Multiply square matrices of same dimension M and N"""
    # Converts N into a list of tuples of columns                                                                     
    tuple_N = zip(*N)

    # Nested list comprehension to calculate matrix multiplication                                                    
    return [[sum(el_m * el_n for el_m, el_n in zip(row_m, col_n)) for col_n in tuple_N] for row_m in M]

def trans_matrix(M):
    """Take the transpose of a matrix."""
    n = len(M)
    return [[ M[i][j] for i in range(n)] for j in range(n)]

def norm(x):
    """Return the Euclidean norm of the vector x."""
    return sqrt(sum([x_i**2 for x_i in x]))

def Q_i(Q_min, i, j, k):
    """Construct the Q_t matrix by left-top padding the matrix Q                                                      
    with elements from the identity matrix."""
    if i < k or j < k:
        return float(i == j)
    else:
        return Q_min[i-k][j-k]

def householder(A):
    """Performs a Householder Reflections based QR Decomposition of the                                               
    matrix A. The function returns Q, an orthogonal matrix and R, an                                                  
    upper triangular matrix such that A = QR."""
    n = len(A)

    # Set R equal to A, and create Q as a zero matrix of the same size
    R = A
    Q = [[0.0] * n]
    
    # The Householder procedure
    for k in range(n-1):  # We don't perform the procedure on a 1x1 matrix, so we reduce the index by 1
        # Create identity matrix of same size as A                                                                    
        I = [[float(i == j) for i in xrange(n)] for j in xrange(n)]

        # Create the vectors x, e and the scalar alpha
        # Python does not have a sgn function, so we use cmp instead
        x = [row[k] for row in R[k:]]
        e = [row[k] for row in I[k:]]
        alpha = -cmp(x[0],0) * norm(x)

        # Using anonymous functions, we create u and v
        u = map(lambda p,q: p + alpha * q, x, e)
        norm_u = norm(u)
        v = map(lambda p: p/norm_u, u)

        # Create the Q minor matrix
        Q_min = [ [float(i==j) - 2.0 * v[i] * v[j] for i in xrange(n-k)] for j in xrange(n-k) ]

        # "Pad out" the Q minor matrix with elements from the identity
        Q_t = [[ Q_i(Q_min,i,j,k) for i in xrange(n)] for j in xrange(n)]

        # If this is the first run through, right multiply by A,
        # else right multiply by Q
        if k == 0:
            Q = Q_t
            R = mult_matrix(Q_t,A)
        else:
            Q = mult_matrix(Q_t,Q)
            R = mult_matrix(Q_t,R)

    # Since Q is defined as the product of transposes of Q_t,
    # we need to take the transpose upon returning it
    return trans_matrix(Q), R

A9 = [[12, -51, 4], [6, 167, -68], [-4, 24, -41]]
Q, R = householder(A9)

print("A:",A9)
print("Q:",Q)
print("R:",R)

"""Variance"""

def variance(data):
  n8=len(data)
  mean=sum(data)/n8
  deviations=[(x8-mean)**2 for x8 in data]
  variance=sum(deviations)/n8
  return variance

variance([4,8,6,5,3,2,8,9,2,5])